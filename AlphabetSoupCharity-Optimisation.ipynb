{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EIN</th>\n",
       "      <th>NAME</th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10520599</td>\n",
       "      <td>BLUE KNIGHTS MOTORCYCLE CLUB</td>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10531628</td>\n",
       "      <td>AMERICAN CHESAPEAKE CLUB CHARITABLE TR</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10547893</td>\n",
       "      <td>ST CLOUD PROFESSIONAL FIREFIGHTERS</td>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10553066</td>\n",
       "      <td>SOUTHSIDE ATHLETIC ASSOCIATION</td>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10556103</td>\n",
       "      <td>GENETIC RESEARCH INSTITUTE OF THE DESERT</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        EIN                                      NAME APPLICATION_TYPE  \\\n",
       "0  10520599              BLUE KNIGHTS MOTORCYCLE CLUB              T10   \n",
       "1  10531628    AMERICAN CHESAPEAKE CLUB CHARITABLE TR               T3   \n",
       "2  10547893        ST CLOUD PROFESSIONAL FIREFIGHTERS               T5   \n",
       "3  10553066            SOUTHSIDE ATHLETIC ASSOCIATION               T3   \n",
       "4  10556103  GENETIC RESEARCH INSTITUTE OF THE DESERT               T3   \n",
       "\n",
       "        AFFILIATION CLASSIFICATION      USE_CASE  ORGANIZATION  STATUS  \\\n",
       "0       Independent          C1000    ProductDev   Association       1   \n",
       "1       Independent          C2000  Preservation  Co-operative       1   \n",
       "2  CompanySponsored          C3000    ProductDev   Association       1   \n",
       "3  CompanySponsored          C2000  Preservation         Trust       1   \n",
       "4       Independent          C1000     Heathcare         Trust       1   \n",
       "\n",
       "      INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  IS_SUCCESSFUL  \n",
       "0              0                      N     5000              1  \n",
       "1         1-9999                      N   108590              1  \n",
       "2              0                      N     5000              0  \n",
       "3    10000-24999                      N     6692              1  \n",
       "4  100000-499999                      N   142590              1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "#  Import and read the charity_data.csv.\n",
    "import pandas as pd\n",
    "application_df = pd.read_csv(\"https://static.bc-edx.com/data/dla-1-2/m21/lms/starter/charity_data.csv\")\n",
    "application_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  APPLICATION_TYPE       AFFILIATION CLASSIFICATION      USE_CASE  \\\n",
       "0              T10       Independent          C1000    ProductDev   \n",
       "1               T3       Independent          C2000  Preservation   \n",
       "2               T5  CompanySponsored          C3000    ProductDev   \n",
       "3               T3  CompanySponsored          C2000  Preservation   \n",
       "4               T3       Independent          C1000     Heathcare   \n",
       "\n",
       "   ORGANIZATION  STATUS     INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  \\\n",
       "0   Association       1              0                      N     5000   \n",
       "1  Co-operative       1         1-9999                      N   108590   \n",
       "2   Association       1              0                      N     5000   \n",
       "3         Trust       1    10000-24999                      N     6692   \n",
       "4         Trust       1  100000-499999                      N   142590   \n",
       "\n",
       "   IS_SUCCESSFUL  \n",
       "0              1  \n",
       "1              1  \n",
       "2              0  \n",
       "3              1  \n",
       "4              1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the non-beneficial ID columns, \"EIN\" and \"NAME\".\n",
    "application_df = application_df.drop(columns = [\"EIN\", \"NAME\"])\n",
    "application_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "APPLICATION_TYPE            17\n",
       "AFFILIATION                  6\n",
       "CLASSIFICATION              71\n",
       "USE_CASE                     5\n",
       "ORGANIZATION                 4\n",
       "STATUS                       2\n",
       "INCOME_AMT                   9\n",
       "SPECIAL_CONSIDERATIONS       2\n",
       "ASK_AMT                   8747\n",
       "IS_SUCCESSFUL                2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine the number of unique values in each column.\n",
    "application_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'T3': 27037,\n",
       " 'T4': 1542,\n",
       " 'T6': 1216,\n",
       " 'T5': 1173,\n",
       " 'T19': 1065,\n",
       " 'T8': 737,\n",
       " 'T7': 725,\n",
       " 'T10': 528,\n",
       " 'T9': 156,\n",
       " 'T13': 66,\n",
       " 'T12': 27,\n",
       " 'T2': 16,\n",
       " 'T25': 3,\n",
       " 'T14': 3,\n",
       " 'T29': 2,\n",
       " 'T15': 2,\n",
       " 'T17': 1}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at APPLICATION_TYPE value counts to identify and replace with \"Other\"\n",
    "app_dict = application_df[\"APPLICATION_TYPE\"].value_counts().to_dict()\n",
    "app_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "APPLICATION_TYPE\n",
       "T3       27037\n",
       "Other     2266\n",
       "T4        1542\n",
       "T6        1216\n",
       "T5        1173\n",
       "T19       1065\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose a cutoff value and create a list of application types to be replaced\n",
    "# use the variable name `application_types_to_replace`\n",
    "application_types_to_replace = []\n",
    "for app, count in app_dict.items():\n",
    "    if count < 1000:\n",
    "        application_types_to_replace.append(app)\n",
    "\n",
    "# Replace in dataframe\n",
    "for app in application_types_to_replace:\n",
    "    application_df[\"APPLICATION_TYPE\"] = application_df[\"APPLICATION_TYPE\"].replace(app,\"Other\")\n",
    "\n",
    "# Check to make sure replacement was successful\n",
    "application_df[\"APPLICATION_TYPE\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C1000': 17326,\n",
       " 'C2000': 6074,\n",
       " 'C1200': 4837,\n",
       " 'C3000': 1918,\n",
       " 'C2100': 1883,\n",
       " 'C7000': 777,\n",
       " 'C1700': 287,\n",
       " 'C4000': 194,\n",
       " 'C5000': 116,\n",
       " 'C1270': 114,\n",
       " 'C2700': 104,\n",
       " 'C2800': 95,\n",
       " 'C7100': 75,\n",
       " 'C1300': 58,\n",
       " 'C1280': 50,\n",
       " 'C1230': 36,\n",
       " 'C1400': 34,\n",
       " 'C7200': 32,\n",
       " 'C2300': 32,\n",
       " 'C1240': 30,\n",
       " 'C8000': 20,\n",
       " 'C7120': 18,\n",
       " 'C1500': 16,\n",
       " 'C1800': 15,\n",
       " 'C6000': 15,\n",
       " 'C1250': 14,\n",
       " 'C8200': 11,\n",
       " 'C1238': 10,\n",
       " 'C1278': 10,\n",
       " 'C1235': 9,\n",
       " 'C1237': 9,\n",
       " 'C7210': 7,\n",
       " 'C2400': 6,\n",
       " 'C1720': 6,\n",
       " 'C4100': 6,\n",
       " 'C1257': 5,\n",
       " 'C1600': 5,\n",
       " 'C1260': 3,\n",
       " 'C2710': 3,\n",
       " 'C0': 3,\n",
       " 'C3200': 2,\n",
       " 'C1234': 2,\n",
       " 'C1246': 2,\n",
       " 'C1267': 2,\n",
       " 'C1256': 2,\n",
       " 'C2190': 1,\n",
       " 'C4200': 1,\n",
       " 'C2600': 1,\n",
       " 'C5200': 1,\n",
       " 'C1370': 1,\n",
       " 'C1248': 1,\n",
       " 'C6100': 1,\n",
       " 'C1820': 1,\n",
       " 'C1900': 1,\n",
       " 'C1236': 1,\n",
       " 'C3700': 1,\n",
       " 'C2570': 1,\n",
       " 'C1580': 1,\n",
       " 'C1245': 1,\n",
       " 'C2500': 1,\n",
       " 'C1570': 1,\n",
       " 'C1283': 1,\n",
       " 'C2380': 1,\n",
       " 'C1732': 1,\n",
       " 'C1728': 1,\n",
       " 'C2170': 1,\n",
       " 'C4120': 1,\n",
       " 'C8210': 1,\n",
       " 'C2561': 1,\n",
       " 'C4500': 1,\n",
       " 'C2150': 1}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at CLASSIFICATION value counts to identify and replace with \"Other\"\n",
    "class_dict = application_df[\"CLASSIFICATION\"].value_counts().to_dict()\n",
    "class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLASSIFICATION\n",
       "C1000    17326\n",
       "C2000     6074\n",
       "C1200     4837\n",
       "Other     2261\n",
       "C3000     1918\n",
       "C2100     1883\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose a cutoff value and create a list of classifications to be replaced\n",
    "# use the variable name `classifications_to_replace`\n",
    "classifications_to_replace = []\n",
    "for classifications, count in class_dict.items():\n",
    "    if count < 1000:\n",
    "        classifications_to_replace.append(classifications)\n",
    "\n",
    "# Replace in dataframe\n",
    "for cls in classifications_to_replace:\n",
    "    application_df[\"CLASSIFICATION\"] = application_df[\"CLASSIFICATION\"].replace(cls,\"Other\")\n",
    "\n",
    "# Check to make sure replacement was successful\n",
    "application_df[\"CLASSIFICATION\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical data to numeric with `pd.get_dummies`\n",
    "application_df = pd.get_dummies(application_df, dtype=\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = application_df[\"IS_SUCCESSFUL\"]\n",
    "\n",
    "# Separate the X variable, the features\n",
    "X = application_df.drop(columns = \"IS_SUCCESSFUL\")\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile, Train and Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,050</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,020</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │         \u001b[38;5;34m4,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)             │         \u001b[38;5;34m8,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │         \u001b[38;5;34m4,050\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │         \u001b[38;5;34m1,020\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m21\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,271</span> (67.46 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m17,271\u001b[0m (67.46 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,271</span> (67.46 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m17,271\u001b[0m (67.46 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# Input Layer\n",
    "nn.add(tf.keras.layers.InputLayer(shape=(40,)))\n",
    "\n",
    "# Add hidden layers\n",
    "nn.add(tf.keras.layers.Dense(units=100, activation=\"relu\"))\n",
    "nn.add(tf.keras.layers.Dense(units=80, activation=\"relu\"))\n",
    "nn.add(tf.keras.layers.Dense(units=50, activation=\"relu\"))\n",
    "nn.add(tf.keras.layers.Dense(units=20, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 719us/step - accuracy: 0.7106 - loss: 0.5871\n",
      "Epoch 2/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7267 - loss: 0.5546\n",
      "Epoch 3/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7318 - loss: 0.5526\n",
      "Epoch 4/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 715us/step - accuracy: 0.7353 - loss: 0.5501\n",
      "Epoch 5/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 685us/step - accuracy: 0.7342 - loss: 0.5501\n",
      "Epoch 6/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 979us/step - accuracy: 0.7349 - loss: 0.5506\n",
      "Epoch 7/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 783us/step - accuracy: 0.7312 - loss: 0.5532\n",
      "Epoch 8/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 662us/step - accuracy: 0.7374 - loss: 0.5473\n",
      "Epoch 9/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 695us/step - accuracy: 0.7337 - loss: 0.5461\n",
      "Epoch 10/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 645us/step - accuracy: 0.7340 - loss: 0.5503\n",
      "Epoch 11/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 643us/step - accuracy: 0.7323 - loss: 0.5502\n",
      "Epoch 12/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 643us/step - accuracy: 0.7376 - loss: 0.5477\n",
      "Epoch 13/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 747us/step - accuracy: 0.7375 - loss: 0.5449\n",
      "Epoch 14/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 643us/step - accuracy: 0.7409 - loss: 0.5429\n",
      "Epoch 15/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 716us/step - accuracy: 0.7320 - loss: 0.5509\n",
      "Epoch 16/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 660us/step - accuracy: 0.7401 - loss: 0.5446\n",
      "Epoch 17/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 654us/step - accuracy: 0.7386 - loss: 0.5439\n",
      "Epoch 18/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 652us/step - accuracy: 0.7377 - loss: 0.5424\n",
      "Epoch 19/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 918us/step - accuracy: 0.7365 - loss: 0.5453\n",
      "Epoch 20/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 647us/step - accuracy: 0.7364 - loss: 0.5455\n",
      "Epoch 21/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 644us/step - accuracy: 0.7362 - loss: 0.5436\n",
      "Epoch 22/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step - accuracy: 0.7410 - loss: 0.5425\n",
      "Epoch 23/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 857us/step - accuracy: 0.7401 - loss: 0.5405\n",
      "Epoch 24/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 700us/step - accuracy: 0.7404 - loss: 0.5407\n",
      "Epoch 25/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 797us/step - accuracy: 0.7370 - loss: 0.5435\n",
      "Epoch 26/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 669us/step - accuracy: 0.7414 - loss: 0.5370\n",
      "Epoch 27/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7375 - loss: 0.5438\n",
      "Epoch 28/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7393 - loss: 0.5410\n",
      "Epoch 29/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7347 - loss: 0.5466\n",
      "Epoch 30/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7385 - loss: 0.5428\n",
      "Epoch 31/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 705us/step - accuracy: 0.7353 - loss: 0.5439\n",
      "Epoch 32/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 820us/step - accuracy: 0.7347 - loss: 0.5425\n",
      "Epoch 33/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7349 - loss: 0.5405\n",
      "Epoch 34/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 760us/step - accuracy: 0.7397 - loss: 0.5414\n",
      "Epoch 35/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 877us/step - accuracy: 0.7313 - loss: 0.5472\n",
      "Epoch 36/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 723us/step - accuracy: 0.7392 - loss: 0.5398\n",
      "Epoch 37/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 766us/step - accuracy: 0.7404 - loss: 0.5393\n",
      "Epoch 38/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 765us/step - accuracy: 0.7417 - loss: 0.5370\n",
      "Epoch 39/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 735us/step - accuracy: 0.7390 - loss: 0.5389\n",
      "Epoch 40/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7378 - loss: 0.5413\n",
      "Epoch 41/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 667us/step - accuracy: 0.7424 - loss: 0.5362\n",
      "Epoch 42/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 649us/step - accuracy: 0.7417 - loss: 0.5357\n",
      "Epoch 43/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 760us/step - accuracy: 0.7378 - loss: 0.5407\n",
      "Epoch 44/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 693us/step - accuracy: 0.7383 - loss: 0.5414\n",
      "Epoch 45/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 678us/step - accuracy: 0.7327 - loss: 0.5442\n",
      "Epoch 46/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 771us/step - accuracy: 0.7379 - loss: 0.5413\n",
      "Epoch 47/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 646us/step - accuracy: 0.7350 - loss: 0.5431\n",
      "Epoch 48/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 768us/step - accuracy: 0.7425 - loss: 0.5364\n",
      "Epoch 49/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 942us/step - accuracy: 0.7373 - loss: 0.5426\n",
      "Epoch 50/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 674us/step - accuracy: 0.7335 - loss: 0.5427\n",
      "Epoch 51/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 764us/step - accuracy: 0.7366 - loss: 0.5398\n",
      "Epoch 52/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 893us/step - accuracy: 0.7337 - loss: 0.5409\n",
      "Epoch 53/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 740us/step - accuracy: 0.7384 - loss: 0.5423\n",
      "Epoch 54/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 829us/step - accuracy: 0.7366 - loss: 0.5404\n",
      "Epoch 55/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 781us/step - accuracy: 0.7362 - loss: 0.5406\n",
      "Epoch 56/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 671us/step - accuracy: 0.7311 - loss: 0.5435\n",
      "Epoch 57/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 799us/step - accuracy: 0.7388 - loss: 0.5387\n",
      "Epoch 58/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 729us/step - accuracy: 0.7374 - loss: 0.5415\n",
      "Epoch 59/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 770us/step - accuracy: 0.7371 - loss: 0.5407\n",
      "Epoch 60/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 653us/step - accuracy: 0.7414 - loss: 0.5346\n",
      "Epoch 61/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 789us/step - accuracy: 0.7447 - loss: 0.5300\n",
      "Epoch 62/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 922us/step - accuracy: 0.7350 - loss: 0.5422\n",
      "Epoch 63/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7398 - loss: 0.5384\n",
      "Epoch 64/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 667us/step - accuracy: 0.7377 - loss: 0.5376\n",
      "Epoch 65/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 673us/step - accuracy: 0.7385 - loss: 0.5381\n",
      "Epoch 66/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 705us/step - accuracy: 0.7398 - loss: 0.5367\n",
      "Epoch 67/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7402 - loss: 0.5385\n",
      "Epoch 68/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 789us/step - accuracy: 0.7397 - loss: 0.5383\n",
      "Epoch 69/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 743us/step - accuracy: 0.7390 - loss: 0.5390\n",
      "Epoch 70/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 735us/step - accuracy: 0.7390 - loss: 0.5393\n",
      "Epoch 71/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 700us/step - accuracy: 0.7360 - loss: 0.5397\n",
      "Epoch 72/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 852us/step - accuracy: 0.7432 - loss: 0.5354\n",
      "Epoch 73/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 766us/step - accuracy: 0.7416 - loss: 0.5339\n",
      "Epoch 74/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7404 - loss: 0.5366\n",
      "Epoch 75/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 668us/step - accuracy: 0.7437 - loss: 0.5330\n",
      "Epoch 76/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 663us/step - accuracy: 0.7415 - loss: 0.5368\n",
      "Epoch 77/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 669us/step - accuracy: 0.7418 - loss: 0.5340\n",
      "Epoch 78/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 663us/step - accuracy: 0.7431 - loss: 0.5333\n",
      "Epoch 79/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 939us/step - accuracy: 0.7397 - loss: 0.5375\n",
      "Epoch 80/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 747us/step - accuracy: 0.7387 - loss: 0.5391\n",
      "Epoch 81/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 667us/step - accuracy: 0.7411 - loss: 0.5364\n",
      "Epoch 82/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 670us/step - accuracy: 0.7421 - loss: 0.5340\n",
      "Epoch 83/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7354 - loss: 0.5422\n",
      "Epoch 84/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 662us/step - accuracy: 0.7391 - loss: 0.5384\n",
      "Epoch 85/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7359 - loss: 0.5381\n",
      "Epoch 86/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 814us/step - accuracy: 0.7432 - loss: 0.5343\n",
      "Epoch 87/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 694us/step - accuracy: 0.7427 - loss: 0.5305\n",
      "Epoch 88/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 765us/step - accuracy: 0.7467 - loss: 0.5291\n",
      "Epoch 89/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 680us/step - accuracy: 0.7457 - loss: 0.5311\n",
      "Epoch 90/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 864us/step - accuracy: 0.7385 - loss: 0.5391\n",
      "Epoch 91/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 663us/step - accuracy: 0.7391 - loss: 0.5381\n",
      "Epoch 92/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 800us/step - accuracy: 0.7424 - loss: 0.5325\n",
      "Epoch 93/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 647us/step - accuracy: 0.7391 - loss: 0.5362\n",
      "Epoch 94/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 691us/step - accuracy: 0.7410 - loss: 0.5350\n",
      "Epoch 95/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 758us/step - accuracy: 0.7410 - loss: 0.5357\n",
      "Epoch 96/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 648us/step - accuracy: 0.7403 - loss: 0.5343\n",
      "Epoch 97/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 754us/step - accuracy: 0.7428 - loss: 0.5347\n",
      "Epoch 98/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 647us/step - accuracy: 0.7443 - loss: 0.5314\n",
      "Epoch 99/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 757us/step - accuracy: 0.7421 - loss: 0.5359\n",
      "Epoch 100/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 650us/step - accuracy: 0.7379 - loss: 0.5390\n",
      "Epoch 101/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 835us/step - accuracy: 0.7368 - loss: 0.5370\n",
      "Epoch 102/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 652us/step - accuracy: 0.7389 - loss: 0.5389\n",
      "Epoch 103/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 748us/step - accuracy: 0.7376 - loss: 0.5402\n",
      "Epoch 104/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 647us/step - accuracy: 0.7429 - loss: 0.5326\n",
      "Epoch 105/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 765us/step - accuracy: 0.7366 - loss: 0.5400\n",
      "Epoch 106/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 681us/step - accuracy: 0.7352 - loss: 0.5389\n",
      "Epoch 107/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 760us/step - accuracy: 0.7423 - loss: 0.5344\n",
      "Epoch 108/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 651us/step - accuracy: 0.7441 - loss: 0.5308\n",
      "Epoch 109/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 792us/step - accuracy: 0.7396 - loss: 0.5339\n",
      "Epoch 110/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 702us/step - accuracy: 0.7440 - loss: 0.5347\n",
      "Epoch 111/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 777us/step - accuracy: 0.7342 - loss: 0.5461\n",
      "Epoch 112/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 670us/step - accuracy: 0.7399 - loss: 0.5387\n",
      "Epoch 113/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 960us/step - accuracy: 0.7416 - loss: 0.5352\n",
      "Epoch 114/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 806us/step - accuracy: 0.7410 - loss: 0.5348\n",
      "Epoch 115/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 664us/step - accuracy: 0.7384 - loss: 0.5361\n",
      "Epoch 116/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 821us/step - accuracy: 0.7409 - loss: 0.5327\n",
      "Epoch 117/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 694us/step - accuracy: 0.7454 - loss: 0.5318\n",
      "Epoch 118/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 801us/step - accuracy: 0.7334 - loss: 0.5423\n",
      "Epoch 119/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 658us/step - accuracy: 0.7392 - loss: 0.5376\n",
      "Epoch 120/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 764us/step - accuracy: 0.7415 - loss: 0.5306\n",
      "Epoch 121/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7424 - loss: 0.5326\n",
      "Epoch 122/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 786us/step - accuracy: 0.7453 - loss: 0.5282\n",
      "Epoch 123/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 655us/step - accuracy: 0.7384 - loss: 0.5337\n",
      "Epoch 124/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 799us/step - accuracy: 0.7378 - loss: 0.5370\n",
      "Epoch 125/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7412 - loss: 0.5331\n",
      "Epoch 126/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 770us/step - accuracy: 0.7391 - loss: 0.5340\n",
      "Epoch 127/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7411 - loss: 0.5353\n",
      "Epoch 128/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7361 - loss: 0.5422\n",
      "Epoch 129/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 776us/step - accuracy: 0.7444 - loss: 0.5308\n",
      "Epoch 130/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7423 - loss: 0.5348\n",
      "Epoch 131/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 685us/step - accuracy: 0.7398 - loss: 0.5364\n",
      "Epoch 132/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 691us/step - accuracy: 0.7449 - loss: 0.5287\n",
      "Epoch 133/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 823us/step - accuracy: 0.7419 - loss: 0.5320\n",
      "Epoch 134/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 683us/step - accuracy: 0.7371 - loss: 0.5390\n",
      "Epoch 135/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 666us/step - accuracy: 0.7398 - loss: 0.5346\n",
      "Epoch 136/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 661us/step - accuracy: 0.7376 - loss: 0.5378\n",
      "Epoch 137/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 776us/step - accuracy: 0.7417 - loss: 0.5326\n",
      "Epoch 138/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 664us/step - accuracy: 0.7449 - loss: 0.5328\n",
      "Epoch 139/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 655us/step - accuracy: 0.7397 - loss: 0.5360\n",
      "Epoch 140/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 753us/step - accuracy: 0.7372 - loss: 0.5387\n",
      "Epoch 141/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 658us/step - accuracy: 0.7387 - loss: 0.5356\n",
      "Epoch 142/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 767us/step - accuracy: 0.7349 - loss: 0.5426\n",
      "Epoch 143/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 776us/step - accuracy: 0.7405 - loss: 0.5352\n",
      "Epoch 144/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 718us/step - accuracy: 0.7434 - loss: 0.5310\n",
      "Epoch 145/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 832us/step - accuracy: 0.7386 - loss: 0.5359\n",
      "Epoch 146/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 856us/step - accuracy: 0.7433 - loss: 0.5315\n",
      "Epoch 147/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 719us/step - accuracy: 0.7368 - loss: 0.5394\n",
      "Epoch 148/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 652us/step - accuracy: 0.7388 - loss: 0.5348\n",
      "Epoch 149/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 792us/step - accuracy: 0.7469 - loss: 0.5288\n",
      "Epoch 150/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 663us/step - accuracy: 0.7373 - loss: 0.5382\n",
      "Epoch 151/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 656us/step - accuracy: 0.7482 - loss: 0.5299\n",
      "Epoch 152/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 764us/step - accuracy: 0.7383 - loss: 0.5356\n",
      "Epoch 153/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 665us/step - accuracy: 0.7433 - loss: 0.5310\n",
      "Epoch 154/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 652us/step - accuracy: 0.7395 - loss: 0.5372\n",
      "Epoch 155/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 763us/step - accuracy: 0.7425 - loss: 0.5318\n",
      "Epoch 156/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 668us/step - accuracy: 0.7439 - loss: 0.5305\n",
      "Epoch 157/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 655us/step - accuracy: 0.7369 - loss: 0.5397\n",
      "Epoch 158/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 753us/step - accuracy: 0.7416 - loss: 0.5343\n",
      "Epoch 159/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 662us/step - accuracy: 0.7406 - loss: 0.5337\n",
      "Epoch 160/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 655us/step - accuracy: 0.7386 - loss: 0.5363\n",
      "Epoch 161/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 771us/step - accuracy: 0.7374 - loss: 0.5340\n",
      "Epoch 162/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 670us/step - accuracy: 0.7407 - loss: 0.5380\n",
      "Epoch 163/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 654us/step - accuracy: 0.7413 - loss: 0.5347\n",
      "Epoch 164/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 754us/step - accuracy: 0.7380 - loss: 0.5359\n",
      "Epoch 165/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 653us/step - accuracy: 0.7355 - loss: 0.5397\n",
      "Epoch 166/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 652us/step - accuracy: 0.7388 - loss: 0.5365\n",
      "Epoch 167/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 764us/step - accuracy: 0.7422 - loss: 0.5317\n",
      "Epoch 168/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 664us/step - accuracy: 0.7443 - loss: 0.5297\n",
      "Epoch 169/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 661us/step - accuracy: 0.7381 - loss: 0.5378\n",
      "Epoch 170/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 789us/step - accuracy: 0.7372 - loss: 0.5377\n",
      "Epoch 171/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 650us/step - accuracy: 0.7404 - loss: 0.5335\n",
      "Epoch 172/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 653us/step - accuracy: 0.7442 - loss: 0.5298\n",
      "Epoch 173/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7425 - loss: 0.5312\n",
      "Epoch 174/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 864us/step - accuracy: 0.7399 - loss: 0.5383\n",
      "Epoch 175/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 927us/step - accuracy: 0.7411 - loss: 0.5337\n",
      "Epoch 176/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 935us/step - accuracy: 0.7385 - loss: 0.5349\n",
      "Epoch 177/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 806us/step - accuracy: 0.7444 - loss: 0.5313\n",
      "Epoch 178/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 821us/step - accuracy: 0.7412 - loss: 0.5339\n",
      "Epoch 179/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 666us/step - accuracy: 0.7412 - loss: 0.5325\n",
      "Epoch 180/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7412 - loss: 0.5382\n",
      "Epoch 181/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 672us/step - accuracy: 0.7402 - loss: 0.5346\n",
      "Epoch 182/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 779us/step - accuracy: 0.7435 - loss: 0.5319\n",
      "Epoch 183/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 837us/step - accuracy: 0.7491 - loss: 0.5316\n",
      "Epoch 184/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 774us/step - accuracy: 0.7398 - loss: 0.5350\n",
      "Epoch 185/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 820us/step - accuracy: 0.7362 - loss: 0.5380\n",
      "Epoch 186/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 672us/step - accuracy: 0.7447 - loss: 0.5322\n",
      "Epoch 187/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7398 - loss: 0.5297\n",
      "Epoch 188/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7378 - loss: 0.5371\n",
      "Epoch 189/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7414 - loss: 0.5353\n",
      "Epoch 190/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 992us/step - accuracy: 0.7457 - loss: 0.5291\n",
      "Epoch 191/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 798us/step - accuracy: 0.7375 - loss: 0.5392\n",
      "Epoch 192/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7421 - loss: 0.5292\n",
      "Epoch 193/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 670us/step - accuracy: 0.7437 - loss: 0.5320\n",
      "Epoch 194/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 701us/step - accuracy: 0.7373 - loss: 0.5380\n",
      "Epoch 195/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 973us/step - accuracy: 0.7408 - loss: 0.5351\n",
      "Epoch 196/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 668us/step - accuracy: 0.7398 - loss: 0.5342\n",
      "Epoch 197/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 993us/step - accuracy: 0.7414 - loss: 0.5324\n",
      "Epoch 198/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 669us/step - accuracy: 0.7410 - loss: 0.5326\n",
      "Epoch 199/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 927us/step - accuracy: 0.7390 - loss: 0.5359\n",
      "Epoch 200/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 697us/step - accuracy: 0.7426 - loss: 0.5330\n",
      "Epoch 201/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 956us/step - accuracy: 0.7450 - loss: 0.5290\n",
      "Epoch 202/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 693us/step - accuracy: 0.7447 - loss: 0.5286\n",
      "Epoch 203/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 963us/step - accuracy: 0.7491 - loss: 0.5249\n",
      "Epoch 204/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 742us/step - accuracy: 0.7379 - loss: 0.5370\n",
      "Epoch 205/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 905us/step - accuracy: 0.7389 - loss: 0.5366\n",
      "Epoch 206/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 731us/step - accuracy: 0.7396 - loss: 0.5352\n",
      "Epoch 207/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 928us/step - accuracy: 0.7375 - loss: 0.5373\n",
      "Epoch 208/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 694us/step - accuracy: 0.7480 - loss: 0.5266\n",
      "Epoch 209/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 965us/step - accuracy: 0.7422 - loss: 0.5336\n",
      "Epoch 210/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 702us/step - accuracy: 0.7441 - loss: 0.5324\n",
      "Epoch 211/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 971us/step - accuracy: 0.7429 - loss: 0.5348\n",
      "Epoch 212/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 673us/step - accuracy: 0.7357 - loss: 0.5367\n",
      "Epoch 213/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 974us/step - accuracy: 0.7451 - loss: 0.5306\n",
      "Epoch 214/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 663us/step - accuracy: 0.7393 - loss: 0.5339\n",
      "Epoch 215/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 938us/step - accuracy: 0.7407 - loss: 0.5373\n",
      "Epoch 216/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 664us/step - accuracy: 0.7424 - loss: 0.5321\n",
      "Epoch 217/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 969us/step - accuracy: 0.7396 - loss: 0.5350\n",
      "Epoch 218/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 671us/step - accuracy: 0.7360 - loss: 0.5374\n",
      "Epoch 219/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7424 - loss: 0.5339\n",
      "Epoch 220/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 663us/step - accuracy: 0.7408 - loss: 0.5329\n",
      "Epoch 221/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7414 - loss: 0.5359\n",
      "Epoch 222/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 664us/step - accuracy: 0.7439 - loss: 0.5424\n",
      "Epoch 223/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 990us/step - accuracy: 0.7378 - loss: 0.5366\n",
      "Epoch 224/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 668us/step - accuracy: 0.7446 - loss: 0.5309\n",
      "Epoch 225/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 969us/step - accuracy: 0.7423 - loss: 0.5315\n",
      "Epoch 226/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 660us/step - accuracy: 0.7425 - loss: 0.5304\n",
      "Epoch 227/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 993us/step - accuracy: 0.7448 - loss: 0.5316\n",
      "Epoch 228/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 763us/step - accuracy: 0.7401 - loss: 0.5370\n",
      "Epoch 229/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 851us/step - accuracy: 0.7435 - loss: 0.5309\n",
      "Epoch 230/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 818us/step - accuracy: 0.7389 - loss: 0.5373\n",
      "Epoch 231/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 787us/step - accuracy: 0.7400 - loss: 0.5346\n",
      "Epoch 232/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 857us/step - accuracy: 0.7468 - loss: 0.5281\n",
      "Epoch 233/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 773us/step - accuracy: 0.7421 - loss: 0.5334\n",
      "Epoch 234/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7414 - loss: 0.5360\n",
      "Epoch 235/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 726us/step - accuracy: 0.7456 - loss: 0.5281\n",
      "Epoch 236/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 998us/step - accuracy: 0.7446 - loss: 0.5308\n",
      "Epoch 237/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 661us/step - accuracy: 0.7431 - loss: 0.5321\n",
      "Epoch 238/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 948us/step - accuracy: 0.7447 - loss: 0.5320\n",
      "Epoch 239/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7449 - loss: 0.5276\n",
      "Epoch 240/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 687us/step - accuracy: 0.7444 - loss: 0.5301\n",
      "Epoch 241/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7430 - loss: 0.5315\n",
      "Epoch 242/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 720us/step - accuracy: 0.7422 - loss: 0.5337\n",
      "Epoch 243/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7392 - loss: 0.5350\n",
      "Epoch 244/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 722us/step - accuracy: 0.7369 - loss: 0.5369\n",
      "Epoch 245/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 982us/step - accuracy: 0.7380 - loss: 0.5340\n",
      "Epoch 246/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 865us/step - accuracy: 0.7435 - loss: 0.5308\n",
      "Epoch 247/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 830us/step - accuracy: 0.7370 - loss: 0.5379\n",
      "Epoch 248/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 974us/step - accuracy: 0.7445 - loss: 0.5326\n",
      "Epoch 249/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 803us/step - accuracy: 0.7393 - loss: 0.5355\n",
      "Epoch 250/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 873us/step - accuracy: 0.7433 - loss: 0.5287\n",
      "Epoch 251/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 693us/step - accuracy: 0.7365 - loss: 0.5373\n",
      "Epoch 252/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 981us/step - accuracy: 0.7418 - loss: 0.5311\n",
      "Epoch 253/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 900us/step - accuracy: 0.7411 - loss: 0.5330\n",
      "Epoch 254/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 768us/step - accuracy: 0.7402 - loss: 0.5333\n",
      "Epoch 255/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 964us/step - accuracy: 0.7414 - loss: 0.5337\n",
      "Epoch 256/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 730us/step - accuracy: 0.7430 - loss: 0.5346\n",
      "Epoch 257/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7424 - loss: 0.5325\n",
      "Epoch 258/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7408 - loss: 0.5323\n",
      "Epoch 259/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 734us/step - accuracy: 0.7421 - loss: 0.5323\n",
      "Epoch 260/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 986us/step - accuracy: 0.7366 - loss: 0.5352\n",
      "Epoch 261/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 959us/step - accuracy: 0.7436 - loss: 0.5294\n",
      "Epoch 262/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 765us/step - accuracy: 0.7442 - loss: 0.5276\n",
      "Epoch 263/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 971us/step - accuracy: 0.7433 - loss: 0.5331\n",
      "Epoch 264/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 687us/step - accuracy: 0.7445 - loss: 0.5291\n",
      "Epoch 265/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 996us/step - accuracy: 0.7394 - loss: 0.5348\n",
      "Epoch 266/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 851us/step - accuracy: 0.7379 - loss: 0.5363\n",
      "Epoch 267/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 793us/step - accuracy: 0.7418 - loss: 0.5325\n",
      "Epoch 268/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 946us/step - accuracy: 0.7419 - loss: 0.5308\n",
      "Epoch 269/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 817us/step - accuracy: 0.7428 - loss: 0.5322\n",
      "Epoch 270/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 849us/step - accuracy: 0.7427 - loss: 0.5343\n",
      "Epoch 271/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 928us/step - accuracy: 0.7391 - loss: 0.5369\n",
      "Epoch 272/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 739us/step - accuracy: 0.7437 - loss: 0.5320\n",
      "Epoch 273/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 959us/step - accuracy: 0.7444 - loss: 0.5303\n",
      "Epoch 274/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 808us/step - accuracy: 0.7419 - loss: 0.5340\n",
      "Epoch 275/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 838us/step - accuracy: 0.7466 - loss: 0.5276\n",
      "Epoch 276/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7387 - loss: 0.5488\n",
      "Epoch 277/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 929us/step - accuracy: 0.7414 - loss: 0.5312\n",
      "Epoch 278/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 764us/step - accuracy: 0.7487 - loss: 0.5269\n",
      "Epoch 279/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 951us/step - accuracy: 0.7436 - loss: 0.5288\n",
      "Epoch 280/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 719us/step - accuracy: 0.7415 - loss: 0.5347\n",
      "Epoch 281/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7425 - loss: 0.5302\n",
      "Epoch 282/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 866us/step - accuracy: 0.7423 - loss: 0.5317\n",
      "Epoch 283/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 824us/step - accuracy: 0.7435 - loss: 0.5300\n",
      "Epoch 284/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 918us/step - accuracy: 0.7369 - loss: 0.5392\n",
      "Epoch 285/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 749us/step - accuracy: 0.7356 - loss: 0.5383\n",
      "Epoch 286/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 963us/step - accuracy: 0.7395 - loss: 0.5367\n",
      "Epoch 287/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 921us/step - accuracy: 0.7409 - loss: 0.5352\n",
      "Epoch 288/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 786us/step - accuracy: 0.7418 - loss: 0.5323\n",
      "Epoch 289/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 997us/step - accuracy: 0.7440 - loss: 0.5319\n",
      "Epoch 290/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 946us/step - accuracy: 0.7381 - loss: 0.5335\n",
      "Epoch 291/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 860us/step - accuracy: 0.7427 - loss: 0.5344\n",
      "Epoch 292/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 991us/step - accuracy: 0.7365 - loss: 0.5355\n",
      "Epoch 293/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 838us/step - accuracy: 0.7409 - loss: 0.5330\n",
      "Epoch 294/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 842us/step - accuracy: 0.7427 - loss: 0.5320\n",
      "Epoch 295/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 985us/step - accuracy: 0.7405 - loss: 0.5322\n",
      "Epoch 296/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 841us/step - accuracy: 0.7483 - loss: 0.5259\n",
      "Epoch 297/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 830us/step - accuracy: 0.7408 - loss: 0.5335\n",
      "Epoch 298/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 964us/step - accuracy: 0.7421 - loss: 0.5340\n",
      "Epoch 299/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 871us/step - accuracy: 0.7421 - loss: 0.5335\n",
      "Epoch 300/300\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 811us/step - accuracy: 0.7478 - loss: 0.5280\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 0s - 696us/step - accuracy: 0.7259 - loss: 0.6394\n",
      "Loss: 0.639424204826355, Accuracy: 0.7259474992752075\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Export our model to HDF5 file\n",
    "nn.save(\"Model_Results/AlphabetSoupCharity_Optimisation_2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
